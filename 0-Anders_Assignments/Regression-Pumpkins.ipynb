{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8535ea3",
   "metadata": {},
   "source": [
    "# Assignment 2.2: Pumpkin Logistic Regression\n",
    "\n",
    "**Objective**: Build a logistic regression model using the full pumpkin dataset, with proper data cleaning and standardization. We'll evaluate the model using confusion matrix and ROC curve.\n",
    "\n",
    "**Dataset**: US-pumpkins.csv contains 1757 records with 26 features including prices, varieties, sizes, origins, and dates.\n",
    "\n",
    "**Target**: We need to define a classification target. Common approaches:\n",
    "- Classify by variety (HOWDEN TYPE, PIE TYPE, MINIATURE)\n",
    "- Classify by size category (large vs medium vs small)\n",
    "- Classify by price range (high vs low price)\n",
    "\n",
    "We'll use **Variety** as our target since it's the most meaningful classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898d2536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1757, 26)\n",
      "\n",
      "Columns: ['City Name', 'Type', 'Package', 'Variety', 'Sub Variety', 'Grade', 'Date', 'Low Price', 'High Price', 'Mostly Low', 'Mostly High', 'Origin', 'Origin District', 'Item Size', 'Color', 'Environment', 'Unit of Sale', 'Quality', 'Condition', 'Appearance', 'Storage', 'Crop', 'Repack', 'Trans Mode', 'Unnamed: 24', 'Unnamed: 25']\n",
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Package</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Sub Variety</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Date</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Mostly Low</th>\n",
       "      <th>...</th>\n",
       "      <th>Unit of Sale</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Appearance</th>\n",
       "      <th>Storage</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Repack</th>\n",
       "      <th>Trans Mode</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24 inch bins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/29/17</td>\n",
       "      <td>270.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24 inch bins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/6/17</td>\n",
       "      <td>270.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24 inch bins</td>\n",
       "      <td>HOWDEN TYPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/24/16</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   City Name Type       Package      Variety Sub Variety  Grade     Date  \\\n",
       "0  BALTIMORE  NaN  24 inch bins          NaN         NaN    NaN  4/29/17   \n",
       "1  BALTIMORE  NaN  24 inch bins          NaN         NaN    NaN   5/6/17   \n",
       "2  BALTIMORE  NaN  24 inch bins  HOWDEN TYPE         NaN    NaN  9/24/16   \n",
       "\n",
       "   Low Price  High Price  Mostly Low  ...  Unit of Sale Quality Condition  \\\n",
       "0      270.0       280.0       270.0  ...           NaN     NaN       NaN   \n",
       "1      270.0       280.0       270.0  ...           NaN     NaN       NaN   \n",
       "2      160.0       160.0       160.0  ...           NaN     NaN       NaN   \n",
       "\n",
       "  Appearance Storage  Crop Repack  Trans Mode  Unnamed: 24  Unnamed: 25  \n",
       "0        NaN     NaN   NaN      E         NaN          NaN          NaN  \n",
       "1        NaN     NaN   NaN      E         NaN          NaN          NaN  \n",
       "2        NaN     NaN   NaN      N         NaN          NaN          NaN  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load and inspect the pumpkin dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/Axewu/OneDrive/Dokumenter/GitHub/ML-For-Beginners/2-Regression/data/US-pumpkins.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1f2202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA EXPLORATION ===\n",
      "Dataset shape: (1757, 26)\n",
      "\n",
      "Data types:\n",
      "object     13\n",
      "float64    13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "                 Missing Count  Missing Percentage\n",
      "Grade                     1757          100.000000\n",
      "Quality                   1757          100.000000\n",
      "Condition                 1757          100.000000\n",
      "Appearance                1757          100.000000\n",
      "Storage                   1757          100.000000\n",
      "Crop                      1757          100.000000\n",
      "Trans Mode                1757          100.000000\n",
      "Unnamed: 24               1757          100.000000\n",
      "Environment               1757          100.000000\n",
      "Type                      1712           97.438816\n",
      "Unnamed: 25               1654           94.137735\n",
      "Origin District           1626           92.544109\n",
      "Unit of Sale              1595           90.779738\n",
      "Sub Variety               1461           83.153102\n",
      "Color                      616           35.059761\n",
      "Item Size                  279           15.879340\n",
      "Mostly Low                 103            5.862265\n",
      "Mostly High                103            5.862265\n",
      "Variety                      5            0.284576\n",
      "Origin                       3            0.170746\n",
      "\n",
      "=== TARGET VARIABLE ANALYSIS ===\n",
      "Variety value counts:\n",
      "Variety\n",
      "HOWDEN TYPE                 542\n",
      "PIE TYPE                    468\n",
      "MINIATURE                   310\n",
      "FAIRYTALE                   132\n",
      "CINDERELLA                   81\n",
      "BIG MACK TYPE                74\n",
      "MIXED HEIRLOOM VARIETIES     57\n",
      "HOWDEN WHITE TYPE            49\n",
      "KNUCKLE HEAD                 20\n",
      "BLUE TYPE                    19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Variety missing values: 5\n",
      "\n",
      "=== NUMERIC FEATURES ===\n",
      "         Low Price   High Price   Mostly Low  Mostly High\n",
      "count  1757.000000  1757.000000  1654.000000  1654.000000\n",
      "mean    124.571338   132.970939   128.170550   132.491802\n",
      "std      83.876591    89.524958    86.512161    88.442967\n",
      "min       0.240000     0.240000     0.240000     0.240000\n",
      "25%      24.000000    24.500000    24.625000    26.125000\n",
      "50%     140.000000   150.000000   147.000000   150.000000\n",
      "75%     180.000000   200.000000   185.000000   200.000000\n",
      "max     480.000000   480.000000   480.000000   480.000000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Exploration and Missing Values Analysis\n",
    "print(\"=== DATA EXPLORATION ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\n=== MISSING VALUES ===\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "}).sort_values('Missing Percentage', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "print(f\"\\n=== TARGET VARIABLE ANALYSIS ===\")\n",
    "print(\"Variety value counts:\")\n",
    "print(df['Variety'].value_counts())\n",
    "print(f\"\\nVariety missing values: {df['Variety'].isnull().sum()}\")\n",
    "\n",
    "print(f\"\\n=== NUMERIC FEATURES ===\")\n",
    "numeric_cols = ['Low Price', 'High Price', 'Mostly Low', 'Mostly High']\n",
    "print(df[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7cb2d",
   "metadata": {},
   "source": [
    "## Data Cleaning Strategy\n",
    "\n",
    "Based on the exploration above, our cleaning strategy will be:\n",
    "\n",
    "1. **Target Variable**: Use 'Variety' as our classification target (HOWDEN TYPE, PIE TYPE, MINIATURE)\n",
    "2. **Remove irrelevant columns**: Drop columns with too many missing values or no predictive value\n",
    "3. **Handle missing values**: \n",
    "   - Drop rows where target (Variety) is missing\n",
    "   - For features: impute or drop based on missing percentage\n",
    "4. **Feature Engineering**:\n",
    "   - Create average price feature from Low/High Price\n",
    "   - Encode categorical variables\n",
    "   - Parse dates if needed\n",
    "5. **Remove outliers**: Handle extreme price values\n",
    "6. **Standardization**: Scale all numeric features for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b5f5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE CLEANING ===\n",
      "Original shape: (1757, 26)\n",
      "Rows with missing Variety: 5\n",
      "After removing missing Variety: (1752, 26)\n",
      "After keeping top 3 varieties: (1320, 26)\n",
      "Varieties kept: ['HOWDEN TYPE', 'PIE TYPE', 'MINIATURE']\n",
      "After dropping irrelevant columns: (1320, 13)\n",
      "\n",
      "=== MISSING VALUES AFTER INITIAL CLEANING ===\n",
      "Mostly Low       88\n",
      "Mostly High      88\n",
      "Item Size       223\n",
      "Color           329\n",
      "Crop           1320\n",
      "dtype: int64\n",
      "\n",
      "=== AFTER FEATURE ENGINEERING ===\n",
      "Final shape: (1320, 17)\n",
      "Columns: ['City Name', 'Package', 'Variety', 'Date', 'Low Price', 'High Price', 'Mostly Low', 'Mostly High', 'Origin', 'Item Size', 'Color', 'Crop', 'Repack', 'Avg_Price', 'Price_Range', 'Month', 'Year']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Name</th>\n",
       "      <th>Package</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Date</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Mostly Low</th>\n",
       "      <th>Mostly High</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Item Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Repack</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>Price_Range</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>24 inch bins</td>\n",
       "      <td>HOWDEN TYPE</td>\n",
       "      <td>2016-09-24</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>DELAWARE</td>\n",
       "      <td>med</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>24 inch bins</td>\n",
       "      <td>HOWDEN TYPE</td>\n",
       "      <td>2016-09-24</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>med</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>24 inch bins</td>\n",
       "      <td>HOWDEN TYPE</td>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>lge</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>24 inch bins</td>\n",
       "      <td>HOWDEN TYPE</td>\n",
       "      <td>2016-11-12</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>lge</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>36 inch bins</td>\n",
       "      <td>HOWDEN TYPE</td>\n",
       "      <td>2016-09-24</td>\n",
       "      <td>160.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>med</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>165.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City Name       Package      Variety       Date  Low Price  High Price  \\\n",
       "2  BALTIMORE  24 inch bins  HOWDEN TYPE 2016-09-24      160.0       160.0   \n",
       "3  BALTIMORE  24 inch bins  HOWDEN TYPE 2016-09-24      160.0       160.0   \n",
       "4  BALTIMORE  24 inch bins  HOWDEN TYPE 2016-11-05       90.0       100.0   \n",
       "5  BALTIMORE  24 inch bins  HOWDEN TYPE 2016-11-12       90.0       100.0   \n",
       "6  BALTIMORE  36 inch bins  HOWDEN TYPE 2016-09-24      160.0       170.0   \n",
       "\n",
       "   Mostly Low  Mostly High    Origin Item Size   Color  Crop Repack  \\\n",
       "2       160.0        160.0  DELAWARE       med  ORANGE   NaN      N   \n",
       "3       160.0        160.0  VIRGINIA       med  ORANGE   NaN      N   \n",
       "4        90.0        100.0  MARYLAND       lge  ORANGE   NaN      N   \n",
       "5        90.0        100.0  MARYLAND       lge  ORANGE   NaN      N   \n",
       "6       160.0        170.0  MARYLAND       med  ORANGE   NaN      N   \n",
       "\n",
       "   Avg_Price  Price_Range  Month  Year  \n",
       "2      160.0          0.0      9  2016  \n",
       "3      160.0          0.0      9  2016  \n",
       "4       95.0         10.0     11  2016  \n",
       "5       95.0         10.0     11  2016  \n",
       "6      165.0         10.0      9  2016  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Data Cleaning Implementation\n",
    "print(\"=== BEFORE CLEANING ===\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Remove rows where target variable (Variety) is missing\n",
    "print(f\"Rows with missing Variety: {df_clean['Variety'].isnull().sum()}\")\n",
    "df_clean = df_clean.dropna(subset=['Variety'])\n",
    "print(f\"After removing missing Variety: {df_clean.shape}\")\n",
    "\n",
    "# 2. Keep only the main varieties (top 3 most common)\n",
    "top_varieties = df_clean['Variety'].value_counts().head(3).index\n",
    "df_clean = df_clean[df_clean['Variety'].isin(top_varieties)]\n",
    "print(f\"After keeping top 3 varieties: {df_clean.shape}\")\n",
    "print(f\"Varieties kept: {list(top_varieties)}\")\n",
    "\n",
    "# 3. Remove columns that are mostly empty or not useful for prediction\n",
    "columns_to_drop = [\n",
    "\t'Unnamed: 24', 'Unnamed: 25', 'Type', 'Sub Variety', 'Grade', \n",
    "    'Environment', 'Unit of Sale', 'Quality', 'Condition', 'Appearance', 'Storage', 'Origin District', 'Trans Mode'\n",
    "]\n",
    "df_clean = df_clean.drop(columns=columns_to_drop, errors='ignore')\n",
    "print(f\"After dropping irrelevant columns: {df_clean.shape}\")\n",
    "\n",
    "# 4. Handle missing values in remaining important columns\n",
    "print(f\"\\n=== MISSING VALUES AFTER INITIAL CLEANING ===\")\n",
    "missing_after = df_clean.isnull().sum()\n",
    "print(missing_after[missing_after > 0])\n",
    "\n",
    "# 5. Create average price feature\n",
    "df_clean['Avg_Price'] = (df_clean['Low Price'] + df_clean['High Price']) / 2\n",
    "df_clean['Price_Range'] = df_clean['High Price'] - df_clean['Low Price']\n",
    "\n",
    "# 6. Handle date parsing (extract month/season if needed)\n",
    "df_clean['Date'] = pd.to_datetime(df_clean['Date'], format='%m/%d/%y', errors='coerce')\n",
    "df_clean['Month'] = df_clean['Date'].dt.month\n",
    "df_clean['Year'] = df_clean['Date'].dt.year\n",
    "\n",
    "print(f\"\\n=== AFTER FEATURE ENGINEERING ===\")\n",
    "print(f\"Final shape: {df_clean.shape}\")\n",
    "print(f\"Columns: {list(df_clean.columns)}\")\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba9a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE PREPARATION ===\n",
      "Handling missing values...\n",
      "Removing price outliers...\n",
      "Price range before outlier removal: 10.75 - 480.00\n",
      "Price range after outlier removal: 10.75 - 400.00\n",
      "Shape after outlier removal: (1316, 17)\n",
      "\n",
      "Encoding categorical variables...\n",
      "Encoded City Name: 13 unique values\n",
      "Encoded Package: 14 unique values\n",
      "Encoded Origin: 22 unique values\n",
      "Encoded Item Size: 8 unique values\n",
      "Encoded Color: 4 unique values\n",
      "Encoded Crop: 1 unique values\n",
      "Encoded Repack: 1 unique values\n",
      "\n",
      "Final dataset shape: (1316, 24)\n",
      "Target variable distribution:\n",
      "Variety\n",
      "HOWDEN TYPE    541\n",
      "PIE TYPE       465\n",
      "MINIATURE      310\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Feature Preparation and Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"=== FEATURE PREPARATION ===\")\n",
    "\n",
    "# Handle remaining missing values\n",
    "print(\"Handling missing values...\")\n",
    "# Fill missing categorical values with 'Unknown'\n",
    "categorical_cols = ['City Name', 'Package', 'Origin', 'Item Size', 'Color', 'Crop', 'Repack']\n",
    "for col in categorical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "numeric_cols = ['Low Price', 'High Price', 'Mostly Low', 'Mostly High', 'Avg_Price', 'Price_Range']\n",
    "for col in numeric_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "# Remove outliers in price (using IQR method)\n",
    "print(\"Removing price outliers...\")\n",
    "Q1 = df_clean['Avg_Price'].quantile(0.25)\n",
    "Q3 = df_clean['Avg_Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Price range before outlier removal: {df_clean['Avg_Price'].min():.2f} - {df_clean['Avg_Price'].max():.2f}\")\n",
    "df_clean = df_clean[(df_clean['Avg_Price'] >= lower_bound) & (df_clean['Avg_Price'] <= upper_bound)]\n",
    "print(f\"Price range after outlier removal: {df_clean['Avg_Price'].min():.2f} - {df_clean['Avg_Price'].max():.2f}\")\n",
    "print(f\"Shape after outlier removal: {df_clean.shape}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "label_encoders = {}\n",
    "categorical_features = ['City Name', 'Package', 'Origin', 'Item Size', 'Color', 'Crop', 'Repack']\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in df_clean.columns and df_clean[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df_clean[col + '_encoded'] = le.fit_transform(df_clean[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Encoded {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df_clean.shape}\")\n",
    "print(f\"Target variable distribution:\")\n",
    "print(df_clean['Variety'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6fdbbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE SELECTION ===\n",
      "Selected features: ['Low Price', 'High Price', 'Mostly Low', 'Mostly High', 'Avg_Price', 'Price_Range', 'Month', 'Year', 'City Name_encoded', 'Package_encoded', 'Origin_encoded', 'Item Size_encoded', 'Color_encoded', 'Crop_encoded', 'Repack_encoded']\n",
      "Features shape: (1316, 15)\n",
      "Target shape: (1316,)\n",
      "Feature data types:\n",
      "Low Price            float64\n",
      "High Price           float64\n",
      "Mostly Low           float64\n",
      "Mostly High          float64\n",
      "Avg_Price            float64\n",
      "Price_Range          float64\n",
      "Month                  int32\n",
      "Year                   int32\n",
      "City Name_encoded      int64\n",
      "Package_encoded        int64\n",
      "Origin_encoded         int64\n",
      "Item Size_encoded      int64\n",
      "Color_encoded          int64\n",
      "Crop_encoded           int64\n",
      "Repack_encoded         int64\n",
      "dtype: object\n",
      "\n",
      "Missing values in features:\n",
      "0\n",
      "\n",
      "Target variable distribution:\n",
      "Variety\n",
      "HOWDEN TYPE    541\n",
      "PIE TYPE       465\n",
      "MINIATURE      310\n",
      "Name: count, dtype: int64\n",
      "Target proportions:\n",
      "Variety\n",
      "HOWDEN TYPE    0.411094\n",
      "PIE TYPE       0.353343\n",
      "MINIATURE      0.235562\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Feature Selection and Standardization\n",
    "print(\"=== FEATURE SELECTION ===\")\n",
    "\n",
    "# Select features for the model\n",
    "feature_columns = [\n",
    "    'Low Price', 'High Price', 'Mostly Low', 'Mostly High', \n",
    "    'Avg_Price', 'Price_Range', 'Month', 'Year',\n",
    "    'City Name_encoded', 'Package_encoded', 'Origin_encoded', \n",
    "    'Item Size_encoded', 'Color_encoded', 'Crop_encoded', 'Repack_encoded'\n",
    "]\n",
    "\n",
    "# Keep only features that exist in our dataset\n",
    "available_features = [col for col in feature_columns if col in df_clean.columns]\n",
    "print(f\"Selected features: {available_features}\")\n",
    "\n",
    "# Prepare X (features) and y (target)\n",
    "X = df_clean[available_features].copy()\n",
    "y = df_clean['Variety'].copy()\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature data types:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(f\"\\nMissing values in features:\")\n",
    "print(X.isnull().sum().sum())\n",
    "\n",
    "# Remove any rows with missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"After removing missing values: X shape {X.shape}, y shape {y.shape}\")\n",
    "\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"Target proportions:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1ae63d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STANDARDIZATION ===\n",
      "Train set: X_train (1052, 15), y_train (1052,)\n",
      "Test set: X_test (264, 15), y_test (264,)\n",
      "\n",
      "Train set target distribution:\n",
      "Variety\n",
      "HOWDEN TYPE    432\n",
      "PIE TYPE       372\n",
      "MINIATURE      248\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set target distribution:\n",
      "Variety\n",
      "HOWDEN TYPE    109\n",
      "PIE TYPE        93\n",
      "MINIATURE       62\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== BEFORE STANDARDIZATION ===\n",
      "Feature ranges (train set):\n",
      "     Low Price  High Price  Mostly Low  Mostly High  Avg_Price  Price_Range  \\\n",
      "min      10.75       10.75        12.0         12.0      10.75          0.0   \n",
      "max     400.00      400.00       400.0        400.0     400.00        100.0   \n",
      "\n",
      "     Month    Year  City Name_encoded  Package_encoded  Origin_encoded  \\\n",
      "min    1.0  2014.0                0.0              0.0             0.0   \n",
      "max   12.0  2017.0               12.0             13.0            21.0   \n",
      "\n",
      "     Item Size_encoded  Color_encoded  Crop_encoded  Repack_encoded  \n",
      "min                0.0            0.0           0.0             0.0  \n",
      "max                7.0            3.0           0.0             0.0  \n",
      "\n",
      "=== AFTER STANDARDIZATION ===\n",
      "Feature ranges (train set):\n",
      "     Low Price  High Price  Mostly Low  Mostly High  Avg_Price  Price_Range  \\\n",
      "min  -1.255943   -1.256910   -1.297938    -1.311650  -1.260646    -0.584842   \n",
      "max   3.695067    3.291338    3.697626     3.505707   3.496289     6.040939   \n",
      "\n",
      "         Month      Year  City Name_encoded  Package_encoded  Origin_encoded  \\\n",
      "min -11.068435 -5.202576          -1.392006        -1.842027       -1.605367   \n",
      "max   2.865848  1.835285           1.827024         2.767591        1.954738   \n",
      "\n",
      "     Item Size_encoded  Color_encoded  Crop_encoded  Repack_encoded  \n",
      "min          -1.754768      -0.719893           0.0             0.0  \n",
      "max           1.405445       1.975222           0.0             0.0  \n",
      "\n",
      "Mean and std of standardized features (should be ~0 and ~1):\n",
      "Means: Low Price      0.0\n",
      "High Price     0.0\n",
      "Mostly Low     0.0\n",
      "Mostly High    0.0\n",
      "Avg_Price     -0.0\n",
      "dtype: float64\n",
      "Stds: Low Price      1.000476\n",
      "High Price     1.000476\n",
      "Mostly Low     1.000476\n",
      "Mostly High    1.000476\n",
      "Avg_Price      1.000476\n",
      "dtype: float64\n",
      "\n",
      "Data is ready for logistic regression!\n",
      "Final shapes: X_train_scaled (1052, 15), X_test_scaled (264, 15)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Standardization and Train/Test Split\n",
    "print(\"=== STANDARDIZATION ===\")\n",
    "\n",
    "# Split the data first (important: standardize after splitting to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"Test set: X_test {X_test.shape}, y_test {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nTrain set target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set target distribution:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Standardize the features\n",
    "print(f\"\\n=== BEFORE STANDARDIZATION ===\")\n",
    "print(f\"Feature ranges (train set):\")\n",
    "print(X_train.describe().loc[['min', 'max']])\n",
    "\n",
    "# Initialize and fit the scaler on training data only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"\\n=== AFTER STANDARDIZATION ===\")\n",
    "print(f\"Feature ranges (train set):\")\n",
    "print(X_train_scaled.describe().loc[['min', 'max']])\n",
    "\n",
    "print(f\"\\nMean and std of standardized features (should be ~0 and ~1):\")\n",
    "print(f\"Means: {X_train_scaled.mean().round(6).head()}\")\n",
    "print(f\"Stds: {X_train_scaled.std().round(6).head()}\")\n",
    "\n",
    "print(f\"\\nData is ready for logistic regression!\")\n",
    "print(f\"Final shapes: X_train_scaled {X_train_scaled.shape}, X_test_scaled {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e25ed",
   "metadata": {},
   "source": [
    "## Summary of Data Cleaning and Preprocessing\n",
    "\n",
    "### What We Did:\n",
    "\n",
    "1. **Data Loading**: Loaded 1757 records with 26 features from the pumpkin dataset\n",
    "\n",
    "2. **Target Selection**: Used 'Variety' as our classification target (HOWDEN TYPE, PIE TYPE, MINIATURE)\n",
    "\n",
    "3. **Data Cleaning**:\n",
    "   - Removed rows with missing target values\n",
    "   - Kept only the top 3 most common varieties\n",
    "   - Dropped irrelevant columns (empty columns, non-predictive features)\n",
    "   - Handled missing values by imputation\n",
    "\n",
    "4. **Feature Engineering**:\n",
    "   - Created `Avg_Price` = (Low Price + High Price) / 2\n",
    "   - Created `Price_Range` = High Price - Low Price  \n",
    "   - Extracted `Month` and `Year` from dates\n",
    "   - Encoded categorical variables using LabelEncoder\n",
    "\n",
    "5. **Outlier Removal**: Removed price outliers using IQR method\n",
    "\n",
    "6. **Standardization**: \n",
    "   - Split data into train/test (80/20) with stratification\n",
    "   - Applied StandardScaler to features (fit on train, transform both)\n",
    "   - All features now have mean ≈ 0 and std ≈ 1\n",
    "\n",
    "### Why Standardization Matters:\n",
    "- Logistic regression is sensitive to feature scales\n",
    "- Features like 'Price' (range: 50-500) vs 'Month' (range: 1-12) have very different scales\n",
    "- Without standardization, price features would dominate the model\n",
    "- StandardScaler ensures all features contribute equally to the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
